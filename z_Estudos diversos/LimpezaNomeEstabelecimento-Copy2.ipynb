{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "interior-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sqlalchemy import create_engine\n",
    "import io\n",
    "import re\n",
    "import string \n",
    "import unidecode\n",
    "from numpy.core.defchararray import find\n",
    "from numpy.core.defchararray import replace\n",
    "import fuzzy_pandas as fz\n",
    "from pyjarowinkler.distance import get_jaro_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "norwegian-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "split-welsh",
   "metadata": {},
   "source": [
    "### A query abaixo busca informações da base original de autorizações e traz a cidade com maior número de transações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "german-disco",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataset_filter = pd.read_sql(\"\"\"\n",
    "#                        SELECT *\n",
    "#                         , rank() over (partition by 1 order by total_trans_estabelecimento desc) as rank_autorizacoes_total\n",
    "#                         , nvl(total_valor_estabelecimento / total_trans_estabelecimento, 0) as ticket_medio_estab\n",
    "#                         FROM \n",
    "#                         (\n",
    "#                             SELECT\n",
    "#                             *,\n",
    "#                             sum(autorizacoes) over (partition by nm_estabelecimento) as total_trans_estabelecimento,\n",
    "#                             sum(vl_transacao) over (partition by nm_estabelecimento) as total_valor_estabelecimento,\n",
    "#                             rank() over (partition by nm_estabelecimento order by autorizacoes desc) as rank_autorizacoes_estab\n",
    "#                             FROM\n",
    "#                             (\n",
    "#                             SELECT\n",
    "#                                     auf_nm_unidade_credenciada as nm_estabelecimento,\n",
    "#                                     mcc.gmc_ds_grupo as grupo_mcc,\n",
    "#                                     upper(cli.cli_ds_cidade_corresp) as cidade_cliente,\n",
    "#                                     upper(cli.cli_ds_uf_corresp) as estado_cliente,\n",
    "#                                     sum(aut.auf_vl_real) as vl_transacao,\n",
    "#                                     count(distinct aut.aut_cd_autorizacao) as autorizacoes\n",
    "#                                 FROM\n",
    "#                                     replication.autorizacao aut\n",
    "#                                 INNER JOIN\n",
    "#                                     replication.mcc mcc\n",
    "#                                     ON mcc.mcc_cd_mcc = aut.auf_cd_mcc \n",
    "#                                 LEFT JOIN replication.conta_cartao cc\n",
    "#                                     ON cc.coc_cd_conta_cartao = aut.pla_cd_conta_cartao\n",
    "#                                 LEFT JOIN replication.cliente cli\n",
    "#                                     ON cc.coc_cd_cliente = cli.cli_cd_cliente \n",
    "#                                 WHERE\n",
    "#                                     aut_fl_saque = 'N'\n",
    "#                                     AND aut_fl_limite_utilizado = 'C'\n",
    "#                                     AND aut_cd_unidade_credenciada <> 60024\n",
    "#                                     AND (current_timestamp - aut_dt_autorizacao) <= 30\n",
    "#                                 GROUP BY \n",
    "#                                     auf_nm_unidade_credenciada, mcc.gmc_ds_grupo, cli.cli_ds_cidade_corresp, cli.cli_ds_uf_corresp\n",
    "#                               )\n",
    "#                           )\n",
    "#                         WHERE rank_autorizacoes_estab = 1\n",
    "                                                                          \n",
    "#                          \"\"\", engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e080ed1-7e4a-4c47-a88b-2b0cf5ad0907",
   "metadata": {},
   "outputs": [],
   "source": [
    "#campos necessários: nm_estabelecimento, cidade_cliente\n",
    "#cidade cliente pode ser a cidade mais frequente de compra desse estabelecimento (maiúscula)\n",
    "#serve para realizar a retirada do nome da cidade do final da descrição do estabelecimento\n",
    "\n",
    "dataset_filter = pd.read_sql(\"\"\"\n",
    "  \n",
    "                                                                          \n",
    "                         \"\"\", engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-dining",
   "metadata": {},
   "source": [
    "## Frequencia dos estabelecimentos sem tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ready-tomorrow",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nm_estabelecimento</th>\n",
       "      <th>grupo_mcc</th>\n",
       "      <th>cidade_cliente</th>\n",
       "      <th>estado_cliente</th>\n",
       "      <th>vl_transacao</th>\n",
       "      <th>autorizacoes</th>\n",
       "      <th>total_trans_estabelecimento</th>\n",
       "      <th>total_valor_estabelecimento</th>\n",
       "      <th>rank_autorizacoes_estab</th>\n",
       "      <th>rank_autorizacoes_total</th>\n",
       "      <th>...</th>\n",
       "      <th>index_x</th>\n",
       "      <th>estab_clean_3</th>\n",
       "      <th>indice_sim_2_x</th>\n",
       "      <th>aux_x</th>\n",
       "      <th>index_y</th>\n",
       "      <th>estab_clean_4</th>\n",
       "      <th>indice_sim_2_y</th>\n",
       "      <th>aux_y</th>\n",
       "      <th>meio_pagamento</th>\n",
       "      <th>estab_clean_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UBERBR UBER * PENDING  SAO PAULO     BRA</td>\n",
       "      <td>TRANSPORTE</td>\n",
       "      <td>SAO PAULO</td>\n",
       "      <td>SP</td>\n",
       "      <td>724871.34</td>\n",
       "      <td>49686</td>\n",
       "      <td>1079299</td>\n",
       "      <td>14370181.89</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>UBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NETFLIX.COM            SAO PAULO     BRA</td>\n",
       "      <td>COMPRAS</td>\n",
       "      <td>SAO PAULO</td>\n",
       "      <td>SP</td>\n",
       "      <td>544351.54</td>\n",
       "      <td>18051</td>\n",
       "      <td>720733</td>\n",
       "      <td>24832287.13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NETFLIX COM</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NETFLIX COM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GOOGLE TEMPORARY HOLD  SAO PAULO     BRA</td>\n",
       "      <td>SERVIÇOS</td>\n",
       "      <td>SAO PAULO</td>\n",
       "      <td>SP</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10611</td>\n",
       "      <td>682309</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GOOGLE TEMPORARY HOLD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>GOOGLE TEMPORARY HOLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UBERBR UBER TRIP HELP. SAO PAULO     BRA</td>\n",
       "      <td>TRANSPORTE</td>\n",
       "      <td>SAO PAULO</td>\n",
       "      <td>SP</td>\n",
       "      <td>400842.85</td>\n",
       "      <td>29005</td>\n",
       "      <td>572933</td>\n",
       "      <td>6977484.56</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>UBER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>UBER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IFOOD       *IFOOD     OSASCO        BRA</td>\n",
       "      <td>ALIMENTAÇÃO</td>\n",
       "      <td>SAO PAULO</td>\n",
       "      <td>SP</td>\n",
       "      <td>1251277.30</td>\n",
       "      <td>30183</td>\n",
       "      <td>557572</td>\n",
       "      <td>18303672.97</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IFOOD</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>IFOOD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         nm_estabelecimento    grupo_mcc cidade_cliente  \\\n",
       "0  UBERBR UBER * PENDING  SAO PAULO     BRA   TRANSPORTE      SAO PAULO   \n",
       "1  NETFLIX.COM            SAO PAULO     BRA      COMPRAS      SAO PAULO   \n",
       "2  GOOGLE TEMPORARY HOLD  SAO PAULO     BRA     SERVIÇOS      SAO PAULO   \n",
       "3  UBERBR UBER TRIP HELP. SAO PAULO     BRA   TRANSPORTE      SAO PAULO   \n",
       "4  IFOOD       *IFOOD     OSASCO        BRA  ALIMENTAÇÃO      SAO PAULO   \n",
       "\n",
       "  estado_cliente  vl_transacao  autorizacoes  total_trans_estabelecimento  \\\n",
       "0             SP     724871.34         49686                      1079299   \n",
       "1             SP     544351.54         18051                       720733   \n",
       "2             SP          0.00         10611                       682309   \n",
       "3             SP     400842.85         29005                       572933   \n",
       "4             SP    1251277.30         30183                       557572   \n",
       "\n",
       "   total_valor_estabelecimento  rank_autorizacoes_estab  \\\n",
       "0                  14370181.89                        1   \n",
       "1                  24832287.13                        1   \n",
       "2                         0.00                        1   \n",
       "3                   6977484.56                        1   \n",
       "4                  18303672.97                        1   \n",
       "\n",
       "   rank_autorizacoes_total  ...  index_x estab_clean_3  indice_sim_2_x aux_x  \\\n",
       "0                        1  ...      NaN           NaN             NaN   NaN   \n",
       "1                        2  ...      NaN           NaN             NaN   NaN   \n",
       "2                        3  ...      NaN           NaN             NaN   NaN   \n",
       "3                        4  ...      NaN           NaN             NaN   NaN   \n",
       "4                        5  ...      NaN           NaN             NaN   NaN   \n",
       "\n",
       "   index_y          estab_clean_4  indice_sim_2_y aux_y  meio_pagamento  \\\n",
       "0      NaN                   UBER             NaN   NaN            None   \n",
       "1      NaN            NETFLIX COM             NaN   NaN            None   \n",
       "2      NaN  GOOGLE TEMPORARY HOLD             NaN   NaN            None   \n",
       "3      NaN                   UBER             NaN   NaN            None   \n",
       "4      NaN                  IFOOD             NaN   NaN            None   \n",
       "\n",
       "           estab_clean_5  \n",
       "0                   UBER  \n",
       "1            NETFLIX COM  \n",
       "2  GOOGLE TEMPORARY HOLD  \n",
       "3                   UBER  \n",
       "4                  IFOOD  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_filter.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-sherman",
   "metadata": {},
   "source": [
    "## Parametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "under-uganda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nome_dataset = 'dataset_filter'\n",
    "# nome_estabelec = 'nm_estabelecimento'\n",
    "# cidade_cliente = 'cidade_cliente'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-rachel",
   "metadata": {},
   "source": [
    "## Funções de Preprocessamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fatty-jacket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preproc(x):\n",
    "    x = x.strip()\n",
    "    x = x.upper()\n",
    "    x = unidecode.unidecode(x)\n",
    "    x = re.sub(r'[^\\w\\s]', ' ', x)\n",
    "    x = re.sub(r'\\t', ' ', x)\n",
    "    x = x.replace('     ',' ')\n",
    "    x = x.replace('   ',' ')\n",
    "    x = x.replace('  ',' ')\n",
    "    x = x.strip()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "three-growth",
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_locais = ['SAO PAULO BRA','SAO PAULO  BRA', 'OSASCO  BRA', 'OSASCO BRA', 'JUNDIAI BRA', 'RIO DE JANEIR BRA', \n",
    "                  'GIBRALTAR GIB', 'CURITIBA BRA', 'PATINGA BRA', 'BARUERI BRA', 'VITORIA BRA','FORTALEZA BRA','SALVADOR BRA',\n",
    "                  'PRAIA GRANDE BRA', 'GOVERNADOR VA BRA', 'GUARULHOS BRA','BELO HORIZONT BRA', ' BRA']\n",
    "\n",
    "def retira_locais(x):\n",
    "    for i in strings_locais:\n",
    "        x = x.replace(i,'')\n",
    "        x = x.strip()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "endless-ecuador",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trata_estabelecimentos(x):\n",
    "    x = re.sub(r'(^(?=.*\\bLOJAS)(?=.*AMERICANAS\\b).*$)', 'LOJAS AMERICANAS', x)\n",
    "    #POSSUI UBER E EATS\n",
    "    x = re.sub(r'(?=.*\\bUBER\\b)(?=.*\\bEATS\\b).*$', 'UBER EATS', x)\n",
    "    #POSSUI UBER E NÃO EATS\n",
    "    x = re.sub(r'(?=.*\\bUBER\\b)(?!.*EATS\\b).*$', 'UBER', x)\n",
    "    x = re.sub(r'^(?=.*\\bGOOGLE)(?=.*GARENA\\b).*$', 'GOOGLE GARENA', x)\n",
    "    x = re.sub(r'(?=.*\\bGOOGLE TEMPORARY HOLD\\b).*$', 'GOOGLE TEMPORARY HOLD', x)\n",
    "    x = re.sub(r'(?=.*\\bIFD BR).*$', 'IFOOD', x)\n",
    "    x = re.sub(r'(?=.*\\bIFOOD).*$', 'IFOOD', x)\n",
    "    x = re.sub(r'(?=.*\\bOBOTICARIO).*$', 'OBOTICARIO', x)\n",
    "    x = re.sub(r'(?=.*\\bHNA BOTICARIO).*$', 'OBOTICARIO', x)\n",
    "    x = x.replace('DL GOOGLE','GOOGLE')\n",
    "    x = x.replace('MERCPAG GOOGLEPLAY','GOOGLE PLAY')\n",
    "    x = x.replace('GOOGLEPLAY','GOOGLE PLAY')\n",
    "    x = x.replace('C E A', 'C A MODAS')\n",
    "\n",
    "    #PARA ESSES CASOS EU NÃO QUERO BUSCAR TODA A STRING\n",
    "    x = x.replace('MERCADOPAGO MERC ', 'MERCADOPAGO ')\n",
    "    x = x.replace('MERCPAG MERCADOLIVRE', 'MERCADOLIVRE')\n",
    "    x = x.replace('MERCPAGO', 'MERCADOPAGO')\n",
    "    x = x.replace('MERCPAG', 'MERCADOPAGO')     \n",
    "    x = x.replace('EBANX','')\n",
    "       \n",
    "    x = x.strip()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "reduced-friend",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Não quero considerar os resultados abaixo no tratamento de similaridade de strings\n",
    "retira_inteiro = ['ARMAZEN', 'ARMAZEM', 'SUPERMERCADO','HIPERMERCADO', 'POSTO', 'COMERCIAL', 'DROGARIA', 'DROGARIAS' 'DROGARIA DO', 'DROGARIA DA', 'FARMACIA', 'FARMACIAS', 'FARMACIA DO', 'FARMACIA DA', 'LOJA', 'LOJAS', \n",
    "'MERCADO','MERCADOS', 'PADARIA','PADARIAS', 'CONFEITARIA','CONFEITARIAS', 'SHOPPING', 'ATACADO','ACOUGUE', 'AÇOUGUE' 'CENTRAL', 'CERVEJARIA','CERVEJARIAS', 'CLINICA','CLINICAS', 'DISTRIBUIDORA', 'MERCADINHO', 'MERCANTIL', 'PADARIA E CONFEITARIA',\n",
    "'PANIFICADORA E CONFEIT', 'PANIFICADORA E CONFEITARIA', 'AMERICAN', 'PANIFICADORA', 'PANIFICADORAS']\n",
    "\n",
    "#se tiver parte do nome abaixo não vai considerar o tratamento por similaridade - não iremos aplicar tratamento para postos\n",
    "retira_parte = ['POSTO', 'GOOGLE', 'MERCADO PAGO', 'MERCADOPAGO', 'OBOTICRIO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "apart-doctor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#limpezas iniciais (pre processamento)\n",
    "dataset_filter['estab_clean'] = dataset_filter['nm_estabelecimento'].apply(text_preproc)\n",
    "dataset_filter['estab_clean'] = dataset_filter['estab_clean'].apply(retira_locais)\n",
    "dataset_filter['estab_clean'] = dataset_filter['estab_clean'].apply(trata_estabelecimentos)\n",
    "dataset_filter['estab_clean'] = dataset_filter['estab_clean'].apply(text_preproc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "universal-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retirando a cidade mais frequente entre os clientes - cidade_cliente é parametro\n",
    "City = dataset_filter['cidade_cliente'].values.astype(str)\n",
    "Estab = dataset_filter['estab_clean'].values.astype(str)\n",
    "dataset_filter = dataset_filter.assign(pos = find(Estab, City, start=0, end=None))\n",
    "dataset_filter = dataset_filter.assign(estab_clean_2 = replace(Estab, City, ''))\n",
    "dataset_filter = dataset_filter.assign(pos_espaco = find(Estab, ' ', start=0, end=None))\n",
    "dataset_filter['tam_caract_cidade'] = dataset_filter['cidade_cliente'].str.len()\n",
    "\n",
    "#regras para considerar a limpeza: a - se não encontrou a cidade a coluna vai permanecer como estava; b - só vai retirar cidades com mais de 3 letras, que apareçam após o primeiro espaço e não no início\n",
    "dataset_filter['estab_clean_3'] = np.where(dataset_filter['pos'] == -1, dataset_filter['estab_clean_2'],\n",
    "                                  np.where((dataset_filter['pos'] > 3) & (dataset_filter['pos_espaco'] != -1) \n",
    "                                  & (dataset_filter['pos'] > dataset_filter['pos_espaco']) \n",
    "                                  & (dataset_filter['tam_caract_cidade'] > 3), dataset_filter['estab_clean_2'], dataset_filter['estab_clean']))\n",
    "#retira tokens consecutivos\n",
    "dataset_filter['estab_clean_3'] = dataset_filter['estab_clean_3'].str.replace(r'\\b(\\w+)(\\s+\\1)+\\b', r'\\1')\n",
    "#replica arrays para crossjoin por similaridade\n",
    "dataset_test1 = dataset_filter[['estab_clean_3']]\n",
    "dataset_test2 = dataset_filter[['estab_clean_3']].rename(columns = {'estab_clean_3':'estab_clean_4'})\n",
    "\n",
    "#fuzzy join e índice de similaridade\n",
    "matches_1 = fz.fuzzy_merge(dataset_test1, dataset_test2, left_on=['estab_clean_3'], right_on=['estab_clean_4'], ignore_case=True, method = 'jaro', threshold = 0.85).drop_duplicates()\n",
    "matches_1['indice_sim'] = [get_jaro_distance(x, y) for x, y in zip(matches_1['estab_clean_3'], matches_1['estab_clean_4'])]\n",
    "\n",
    "#critérios para considerar o string como similar\n",
    "matches_1['tam_1'] = matches_1['estab_clean_3'].str.len()\n",
    "matches_1['tam_2'] = matches_1['estab_clean_4'].str.len()\n",
    "texto1 = matches_1['estab_clean_3'].values.astype(str)\n",
    "texto2 = matches_1['estab_clean_4'].values.astype(str)\n",
    "matches_1 = matches_1.assign(pos2 = find(texto1, texto2, start=0, end=None))\n",
    "\n",
    "#vou considerar o match com descrição mais reduzida (menor tamanho). Se a similaridade for abaixo de 98% só vou considerar se uma parte do nome tratado estiver contida na descrição limpa\n",
    "matches_1 = matches_1.query('tam_2 < tam_1').query('(indice_sim < 0.98 and pos2 != -1) or indice_sim >= 0.98')\n",
    "matches_1['ind_sim_inv'] = 1 - matches_1['indice_sim']\n",
    "\n",
    "#retirando a duplicidade do de para e priorizando pelo nome mais reduzido e com similaridade maior\n",
    "matches_2 = matches_1.sort_values(by=['estab_clean_3', 'tam_2', 'ind_sim_inv']).groupby('estab_clean_3').agg({'estab_clean_4':['first'], 'indice_sim':['first']})\n",
    "matches_2.columns = matches_2.columns.droplevel(0)\n",
    "matches_2.reset_index(level=0, inplace=True)\n",
    "matches_2.columns = ['estab_clean_3','estab_clean_4', 'indice_sim_2']\n",
    "matches_2['estab_clean_4'] = matches_2['estab_clean_4'].apply(text_preproc)\n",
    "matches_2 = matches_2[~matches_2['estab_clean_4'].isin(retira_inteiro)]\n",
    "matches_2['aux'] = matches_2['estab_clean_4'].apply(lambda x: 1 if any(i in x for i in retira_parte) else 0)\n",
    "matches_2 = matches_2[matches_2['aux'] == 0]\n",
    "\n",
    "#duplo merge pra acertar pela similaridade de string em duas etapas\n",
    "dataset_filter = dataset_filter.merge(matches_2.reset_index(), how = 'left', on = 'estab_clean_3')\n",
    "dataset_filter['estab_clean_2'] = dataset_filter['estab_clean_3'] \n",
    "dataset_filter = dataset_filter.drop(columns = 'estab_clean_3').rename(columns = {'estab_clean_4':'estab_clean_3'})\n",
    "dataset_filter = dataset_filter.merge(matches_2.reset_index(), how = 'left', on = 'estab_clean_3')\n",
    "dataset_filter['estab_clean_4'] = dataset_filter['estab_clean_3'].fillna(dataset_filter['estab_clean_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "varying-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Meio de pagamento\n",
    "meio_pagamento = ['MERCADOPAGO', 'ALIPAY', 'PAYPAL', 'PAG ', 'AME DIGITAL', 'PIC PAY', 'APPLE COM BI', 'RECARGAP', 'RECARGAPAY', 'RECARGA PAY', '99INAPPPAYMENT']\n",
    "\n",
    "def considera_meio_pgto(x):\n",
    "    for i in meio_pagamento:\n",
    "        if (x.find(i) != -1):\n",
    "            return i\n",
    "   \n",
    "dataset_filter['meio_pagamento'] = dataset_filter['estab_clean_4'].apply(considera_meio_pgto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "constitutional-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "Estab = dataset_filter['estab_clean_4'].values.astype(str)\n",
    "meio_pgto = dataset_filter['meio_pagamento'].values.astype(str)\n",
    "dataset_filter = dataset_filter.assign(estab_clean_5 = replace(Estab, meio_pgto, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "desirable-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabela_final = dataset_filter[['nm_estabelecimento', 'estab_clean_4']].groupby('nm_estabelecimento').agg({'estab_clean_4':['first']})\n",
    "tabela_final.columns = tabela_final.columns.droplevel(0)\n",
    "tabela_final.reset_index(level=0, inplace=True)\n",
    "tabela_final.columns = ['nm_estabelecimento', 'estabelecimento_resumido']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "corresponding-chassis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nm_estabelecimento</th>\n",
       "      <th>estabelecimento_resumido</th>\n",
       "      <th>meio_pagamento</th>\n",
       "      <th>estab_sem_meio_pgto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9829</th>\n",
       "      <td>ZP     *ROSAAZUL KIDS  RIO DE JANEIR BRA</td>\n",
       "      <td>ZP ROSAAZUL KIDS</td>\n",
       "      <td>None</td>\n",
       "      <td>ZP ROSAAZUL KIDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9830</th>\n",
       "      <td>ZP     *SOMOS CORUJA   RIO DE JANEIR BRA</td>\n",
       "      <td>ZP SOMOS CORUJA</td>\n",
       "      <td>None</td>\n",
       "      <td>ZP SOMOS CORUJA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9831</th>\n",
       "      <td>ZP     *TIO PATINHAS   RIO DE JANEIR BRA</td>\n",
       "      <td>ZP TIO PATINHAS</td>\n",
       "      <td>None</td>\n",
       "      <td>ZP TIO PATINHAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9832</th>\n",
       "      <td>ZP *IFOODPOS           RIO DE JANEIR BRA</td>\n",
       "      <td>IFOOD</td>\n",
       "      <td>None</td>\n",
       "      <td>IFOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9833</th>\n",
       "      <td>ZP *SUPERMERCADO       RIO DE JANEIR BRA</td>\n",
       "      <td>ZP SUPERMERCADO</td>\n",
       "      <td>None</td>\n",
       "      <td>ZP SUPERMERCADO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9834</th>\n",
       "      <td>ZP*IFOOD</td>\n",
       "      <td>IFOOD</td>\n",
       "      <td>None</td>\n",
       "      <td>IFOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9835</th>\n",
       "      <td>ZP*IFOOD               RIO DE JANEIR BRA</td>\n",
       "      <td>IFOOD</td>\n",
       "      <td>None</td>\n",
       "      <td>IFOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9836</th>\n",
       "      <td>ZUL DIGITAL            OSASCO        BRA</td>\n",
       "      <td>ZUL DIGITAL</td>\n",
       "      <td>None</td>\n",
       "      <td>ZUL DIGITAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9837</th>\n",
       "      <td>ZUL VALIDACAO          SP            BRA</td>\n",
       "      <td>ZUL VALIDACAO SP</td>\n",
       "      <td>None</td>\n",
       "      <td>ZUL VALIDACAO SP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9838</th>\n",
       "      <td>ZUPPER                 SAO PAULO     BRA</td>\n",
       "      <td>ZUPPER</td>\n",
       "      <td>None</td>\n",
       "      <td>ZUPPER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            nm_estabelecimento estabelecimento_resumido  \\\n",
       "9829  ZP     *ROSAAZUL KIDS  RIO DE JANEIR BRA         ZP ROSAAZUL KIDS   \n",
       "9830  ZP     *SOMOS CORUJA   RIO DE JANEIR BRA          ZP SOMOS CORUJA   \n",
       "9831  ZP     *TIO PATINHAS   RIO DE JANEIR BRA          ZP TIO PATINHAS   \n",
       "9832  ZP *IFOODPOS           RIO DE JANEIR BRA                    IFOOD   \n",
       "9833  ZP *SUPERMERCADO       RIO DE JANEIR BRA          ZP SUPERMERCADO   \n",
       "9834                                  ZP*IFOOD                    IFOOD   \n",
       "9835  ZP*IFOOD               RIO DE JANEIR BRA                    IFOOD   \n",
       "9836  ZUL DIGITAL            OSASCO        BRA              ZUL DIGITAL   \n",
       "9837  ZUL VALIDACAO          SP            BRA         ZUL VALIDACAO SP   \n",
       "9838  ZUPPER                 SAO PAULO     BRA                   ZUPPER   \n",
       "\n",
       "     meio_pagamento estab_sem_meio_pgto  \n",
       "9829           None    ZP ROSAAZUL KIDS  \n",
       "9830           None     ZP SOMOS CORUJA  \n",
       "9831           None     ZP TIO PATINHAS  \n",
       "9832           None               IFOOD  \n",
       "9833           None     ZP SUPERMERCADO  \n",
       "9834           None               IFOOD  \n",
       "9835           None               IFOOD  \n",
       "9836           None         ZUL DIGITAL  \n",
       "9837           None    ZUL VALIDACAO SP  \n",
       "9838           None              ZUPPER  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabela_final.tail(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
