{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os as os\n",
    "import pickle\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from nltk.util import ngrams\n",
    "import nltk\n",
    "import acessos as ac\n",
    "from arabica import arabica_freq\n",
    "from unidecode import unidecode\n",
    "import re\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import plotly.express as px\n",
    "import texthero as hero\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "\n",
    "select \n",
    "msg.id_issue\n",
    ", msg.dt_envio_mensagem\n",
    ", nm_entidade\n",
    ", msg.ds_message\n",
    ", novas_tags.hierarquia_4\n",
    ", novas_tags.fila_de_atendimento\n",
    "from cx_curated_zone.helpshift_issues_messages msg\n",
    "left join \"cx_curated_zone\".\"helpshift_issues\" AS issues_macro ON msg.\"id_issue\" = issues_macro.\"id_issue\"\n",
    "left join \"cx_curated_zone\".\"helpshift_tag_niveis\" AS helpshift_tag ON msg.\"id_issue\" = helpshift_tag.\"id_issue\"\n",
    "left join processed_zone_api_cxm_tags.tags_hierarquia_gerencial as novas_tags ON trim(lower(n3)) = trim(lower(nm_tag_n3))\n",
    "where ds_entidade = 'cliente'\n",
    "and dt_envio_mensagem >= to_date('2022-06-01','yyyy-mm-dd')\n",
    "order by rand() desc\n",
    "limit 50000\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "df = ac.df_athena('flavia-costa', query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_will= ['da', 'em', 'você', 'de', 'ao', 'os', 'que', 'e', 'eu', 'o', 'estou', 'ele','ela','pra', 'pro', 'entao', 'para', 'voce', \n",
    "            'seu', 'sua', 'por', 'sobre', 'mais', 'uma', 'um','como', 'meu', 'com', 'outro','outra','das','dos','foi', 'fiz','pelo','tem','mas',\n",
    "            'este', 'esse','ta', 'to', 'ai', 'la', 'lo', 'lhe', 'ne','pra', 'tá', 'né', 'ah', 'aí', 'dá', 'ó', 'mim', 'então', 'aqui', 'tô', 'pro', 'isso']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções de tratamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_unuseful_messages(text):\n",
    "    '''\n",
    "    Replace automatic and irrelevant (for the project purpose) messages with empty string\n",
    "    '''\n",
    "    unuseful_messages = [\n",
    "        'Outros assuntos',\n",
    "        'Quero falar de outra coisa',\n",
    "        'Quero resolver uma coisa',\n",
    "        'Falar com atendente',\n",
    "        '&Eacute; outra coisa',\n",
    "        '&Eacute; outro assunto',\n",
    "        'Voltar pro come&ccedil;o',\n",
    "        '&Eacute; outro motivo',\n",
    "        'Quero falar com atendente',\n",
    "        'Me mostra as op&ccedil;&otilde;es de antes',\n",
    "        'Quero falar de outro assunto',\n",
    "        '&Eacute; outro assunto',\n",
    "        '&Eacute; outra coisa ',\n",
    "        'N&atilde;o, ainda tenho d&uacute;vidas',\n",
    "        'Nenhuma das op&ccedil;&otilde;es',\n",
    "        'Falar de outra coisa',\n",
    "        'Quero voltar pro come&ccedil;o',\n",
    "        'Voltar pro come&ccedil;o',\n",
    "        'Falar com atendente',\n",
    "        'Pode sim Por favor',\n",
    "        'Não, ainda tenho dúvidas',\n",
    "        'Certo',\n",
    "        'Obrigado',\n",
    "        'Responde'\n",
    "    ]\n",
    "\n",
    "    if text.strip() in unuseful_messages:\n",
    "        return ''\n",
    "\n",
    "    return text\n",
    "def remove_emoji(text):\n",
    "    '''\n",
    "    Replace emojis with empty string\n",
    "    '''\n",
    "    regrex_pattern = re.compile(pattern=\"[\"\n",
    "                                u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                                u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                                u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                                u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                                \"]+\", flags=re.UNICODE)\n",
    "    return regrex_pattern.sub(r'', str(text))\n",
    "def clean_text(x):\n",
    "    x = x.strip()\n",
    "    x = x.lower()\n",
    "    x = unidecode(x)\n",
    "    x = re.sub(r'\\t', ' ', x)\n",
    "    x = re.sub(r'http\\S+', '', x)  # remove url\n",
    "    x = re.sub(r'screenshot sent', 'screenshotsent', x)\n",
    "    x = re.sub(r'will bank', 'willbank', x)\n",
    "    x = re.sub(r'(nbsp\\;|[rl]dquo\\;|quot\\;|acute\\;|tilde\\;|circ\\;|grave\\;|cedil\\;|\\&|\\/)', '', x)  # replace special characters\n",
    "    \n",
    "    x = x.replace('&ccedil;','ç')\n",
    "    x = x.replace('&atilde;;','ã')\n",
    "    x = x.replace('&otilde;;','õ')\n",
    "    x = re.sub(r'(\\d{1,}|\\!|\\?|\\,|\\.|\\\\n|\\:|\\;|\\`|\\´|\\-|\\_)', ' ', x)  # replace punctuation and remove numbers\n",
    "    x = x.replace('  ',' ')\n",
    "    x = x.replace('\\n','')\n",
    "    x = x.strip()\n",
    "    return x\n",
    "def retira_saudacoes(text):\n",
    "       \n",
    "   regex_list = [\n",
    "        'bo[ma] (dia|tarde|noite)',\n",
    "        'agradeco', 'agradecido',\n",
    "        '(tu?do?|esta|tah?) (b[eo]m|cert(inh)?[oa]|ok)',\n",
    "        'ok', 'okay', 'sim',\n",
    "        'oi{1,}e{0,}', 'ola', 'opa',\n",
    "        'beleza', 'blz',\n",
    "        'compreendi(do)?',\n",
    "        'entendi(do)?',\n",
    "        'tendi(do)?',\n",
    "        '(muito|mt)? ?(obrigad[oa]|obg|b[oe]m)',\n",
    "        'b?a{1,10}h?',\n",
    "        'abracos?',\n",
    "        '(por|de) na?da?',\n",
    "        'por (favor|gentileza)'\n",
    "    ]\n",
    "   \n",
    "   regex_list += stopwords_will\n",
    "   pattern = r'\\b(' + '|'.join(regex_list) + r')\\b'\n",
    "   text = re.sub(pattern, '', str(text))\n",
    "   text = text.replace('  ',' ')\n",
    "   return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Tratando texto da mensagem\n",
    "df['ds_message_tratada'] = df['ds_message'].apply(replace_unuseful_messages)\n",
    "df['ds_message_tratada'] = df['ds_message_tratada'].apply(remove_emoji)\n",
    "df['ds_message_tratada'] = df['ds_message_tratada'].apply(clean_text)\n",
    "df['ds_message_tratada'] = df['ds_message_tratada'].apply(retira_saudacoes)\n",
    "\n",
    "## substituindo endereços pela palavra 'endereço'\n",
    "df['ds_message_tratada'] = np.where(df['ds_message_tratada'].str.contains(\"rua\"), 'endereço', df['ds_message_tratada'])\n",
    "df['ds_message_tratada'] = np.where(df['ds_message_tratada'].str.contains(\"cep\"), 'endereço', df['ds_message_tratada'])\n",
    "\n",
    "## substituindo links pela palavra 'url'\n",
    "df['ds_message_tratada'] = np.where(df['ds_message_tratada'].str.contains(\"https\"), 'url', df['ds_message_tratada'])\n",
    "\n",
    "## Substituido todos os códigos pela palavra 'código' - os código encontrados continham wi5, wi9, wi8, yf ou bc\n",
    "df['ds_message_tratada'] = np.where(df['ds_message_tratada'].str.contains(\"wi5\"), 'código', df['ds_message_tratada'])\n",
    "df['ds_message_tratada'] = np.where(df['ds_message_tratada'].str.contains(\"wi9\"), 'código', df['ds_message_tratada'])\n",
    "df['ds_message_tratada'] = np.where(df['ds_message_tratada'].str.contains(\"wi8\"), 'código', df['ds_message_tratada'])\n",
    "df['ds_message_tratada'] = np.where(df['ds_message_tratada'].str.contains(\"bc\"), 'código', df['ds_message_tratada'])\n",
    "df['ds_message_tratada'] = np.where(df['ds_message_tratada'].str.contains(\"yf\"), 'código', df['ds_message_tratada'])\n",
    "##Tratando algumas palavras\n",
    "df['ds_message_tratada'] = df['ds_message_tratada'].str.replace('ª', '')\n",
    "df['ds_message_tratada'] = df['ds_message_tratada'].str.replace('º', '')\n",
    "df['ds_message_tratada'] = df['ds_message_tratada'].str.replace(' r ', ' ')\n",
    "\n",
    "## protocolo / ate dias / voce pode \n",
    "df['ds_message_tratada'] = np.where(df['ds_message_tratada'].str.contains(\"protocolo\"), '', df['ds_message_tratada'])\n",
    "df['ds_message_tratada'] = np.where(df['ds_message_tratada'].str.contains(\"ate dias\"), '', df['ds_message_tratada'])\n",
    "df['ds_message_tratada'] = np.where(df['ds_message_tratada'].str.contains(\"voce pode\"), '', df['ds_message_tratada'])\n",
    "\n",
    "df['ds_message_tratada'] = df['ds_message_tratada'].apply(clean_text)\n",
    "df_clean = df.query('ds_message_tratada != \" \"').query('ds_message_tratada != \"  \"').query('ds_message_tratada != \"\"').query('ds_message_tratada != \"   \"')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando vetorização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/flavia.costa/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese') \n",
    "\n",
    "tfidf = TfidfVectorizer(max_df=0.99, min_df=1, stop_words=stopwords , ngram_range=(3,4), lowercase=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = tfidf.fit_transform(df['ds_message_tratada'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = TruncatedSVD(n_components=10, n_iter=5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 1.00000000e+00,  1.21949134e-10,  2.51196009e-11, ...,\n",
       "        -1.02460386e-09,  6.41080120e-10, -4.13238982e-10],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model.fit_transform(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15975, 91615, 42977, ..., 59618, 43470, 71561])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_topic = nmf_model.components_[0]\n",
    "single_topic.argsort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chave faco transferencias\n",
      "ja cadastrei chave\n",
      "ja cadastrei chave faco\n",
      "nao desejo pedir segunda\n",
      "nao desejo pedir\n",
      "desejo pedir segunda via\n",
      "desejo pedir segunda\n",
      "pedir segunda via\n",
      "nao recebi boleto\n",
      "bloqueio desbloqueio cartao\n",
      "pix nao caiu\n",
      "paguei limite nao\n",
      "paguei limite nao voltou\n",
      "limite nao voltou\n",
      "quero negociar chat\n"
     ]
    }
   ],
   "source": [
    "list=[]\n",
    "top_word_indices = single_topic.argsort()[-15:]\n",
    "for index in top_word_indices:\n",
    "    print(tfidf.get_feature_names()[index])\n",
    "    list.append(tfidf.get_feature_names()[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP WORDS FOR TOPIC #0\n",
      "['consigo pagar tudo', 'nao consigo pagar', 'quero cancelar compra', 'cadastrei chave faco transferencias', 'cadastrei chave faco', 'chave faco transferencias', 'ja cadastrei chave', 'ja cadastrei chave faco', 'nao desejo pedir segunda', 'nao desejo pedir', 'desejo pedir segunda via', 'desejo pedir segunda', 'pedir segunda via', 'nao recebi boleto', 'bloqueio desbloqueio cartao', 'pix nao caiu', 'paguei limite nao', 'paguei limite nao voltou', 'limite nao voltou', 'quero negociar chat']\n",
      "\n",
      "\n",
      "TOP WORDS FOR TOPIC #1\n",
      "['antecipo fatura conta', 'cadastrei chave faco transferencias', 'cadastrei chave faco', 'chave faco transferencias', 'ja cadastrei chave', 'ja cadastrei chave faco', 'saber limite negativo', 'desejo pedir segunda via', 'nao desejo pedir segunda', 'desejo pedir segunda', 'nao desejo pedir', 'pedir segunda via', 'paguei limite nao', 'paguei limite nao voltou', 'limite nao voltou', 'pix nao caiu', 'nao recebi boleto', 'nao ainda preciso ajuda', 'nao ainda preciso', 'ainda preciso ajuda']\n",
      "\n",
      "\n",
      "TOP WORDS FOR TOPIC #2\n",
      "['consigo pagar tudo', 'nao consigo pagar', 'paguei limite nao', 'paguei limite nao voltou', 'limite nao voltou', 'nenhuma dessas duvidas', 'passou prazo nao recebi', 'prazo nao recebi', 'apareceu compra nao', 'ja cadastrei chave faco', 'cadastrei chave faco', 'cadastrei chave faco transferencias', 'chave faco transferencias', 'ja cadastrei chave', 'ja passou prazo nao', 'passou prazo nao', 'antecipo fatura conta', 'ja passou prazo', 'pix nao caiu', 'reconheco todas compras']\n",
      "\n",
      "\n",
      "TOP WORDS FOR TOPIC #3\n",
      "['preciso feito solicitacao', 'tardegostaria pedir nova via', 'boa tardegostaria pedir nova', 'boa tardegostaria pedir', 'tardegostaria pedir nova', 'gostaria pedir nova', 'gostaria pedir nova via', 'quero solicitar nova via', 'quero solicitar nova', 'gostaria solicitar nova', 'gostaria solicitar nova via', 'pedir nova via', 'pedir nova via cartao', 'quero nova via', 'quero nova via cartao', 'solicitar nova via', 'solicitar nova via cartao', 'preciso nova via', 'preciso nova via cartao', 'nova via cartao']\n",
      "\n",
      "\n",
      "TOP WORDS FOR TOPIC #4\n",
      "['nao desejo pedir segunda', 'pedir segunda via', 'bloqueio desbloqueio cartao', 'nao ainda preciso', 'nao ainda preciso ajuda', 'ja cadastrei chave', 'cadastrei chave faco', 'cadastrei chave faco transferencias', 'chave faco transferencias', 'ja cadastrei chave faco', 'compra nao reconheco', 'voltar comeco conversa', 'compra nao autorizada', 'nao recebi boleto', 'paguei limite nao voltou', 'paguei limite nao', 'limite nao voltou', 'mostra opcoes antes', 'quero cancelar compra', 'quero negociar fatura']\n",
      "\n",
      "\n",
      "TOP WORDS FOR TOPIC #5\n",
      "['quero codigo boleto', 'pedir via cartao agora', 'pedir via cartao', 'nao desbloquear cartao', 'ainda preciso ajuda', 'via cartao agora', 'cancelei ainda aparece', 'ja cancelei ainda aparece', 'ja cancelei ainda', 'cancelei ainda aparece fatura', 'ainda aparece fatura', 'ja respondeu duvida', 'pedido ordf via cartao', 'nenhuma dessas duvidas', 'ordf via cartao', 'antecipo fatura conta', 'pedido ordf via', 'apareceu compra nao', 'compra nao reconheco', 'desejo continuar solicitacao']\n",
      "\n",
      "\n",
      "TOP WORDS FOR TOPIC #6\n",
      "['pagar quanto tempo', 'quanto tempo cartao desbloqueado', 'quanto tempo cartao', 'quero codigo boleto', 'consigo pagar tudo', 'nao consigo pagar tudo', 'limite ainda nao', 'ainda nao aumentou', 'limite ainda nao aumentou', 'nao consigo pagar', 'nenhuma dessas duvidas', 'desejo continuar solicitacao', 'compra nao reconheco', 'compras nao reconheco', 'apareceu compra nao', 'voltar comeco conversa', 'quero falar atendimento personalizado', 'falar atendimento personalizado', 'ja respondeu duvida', 'quero falar atendimento']\n",
      "\n",
      "\n",
      "TOP WORDS FOR TOPIC #7\n",
      "['nao ainda preciso ajuda', 'nao ainda preciso', 'pedido entrega cartao', 'nao consigo pagar tudo', 'consigo pagar tudo', 'nao consigo pagar', 'compra nao autorizada', 'limite ainda nao', 'ainda nao aumentou', 'limite ainda nao aumentou', 'nao recebi boleto', 'quero cancelar compra', 'compra nao reconheco', 'voltar comeco conversa', 'mostra opcoes antes', 'quanto tempo limite', 'limite volta pagar', 'tempo limite volta pagar', 'tempo limite volta', 'quanto tempo limite volta']\n",
      "\n",
      "\n",
      "TOP WORDS FOR TOPIC #8\n",
      "['tempo nome sair spc', 'quanto tempo nome sair', 'tempo nome sair', 'quanto tempo nome', 'ja cadastrei chave', 'cadastrei chave faco transferencias', 'ja cadastrei chave faco', 'chave faco transferencias', 'cadastrei chave faco', 'mostra opcoes antes', 'paguei limite nao voltou', 'paguei limite nao', 'limite nao voltou', 'quero cancelar compra', 'compra nao reconheco', 'quanto tempo cartao desbloqueado', 'pagar quanto tempo cartao', 'pagar quanto tempo', 'tempo cartao desbloqueado', 'quanto tempo cartao']\n",
      "\n",
      "\n",
      "TOP WORDS FOR TOPIC #9\n",
      "['so nome sair', 'so nome sair spc', 'nenhuma dessas duvidas', 'pix nao caiu', 'pedido ordf via', 'quero codigo boleto', 'nao ainda preciso ajuda', 'nao ainda preciso', 'limite ainda nao', 'ainda nao aumentou', 'limite ainda nao aumentou', 'apareceu compra nao', 'ja respondeu duvida', 'compras nao reconheco', 'bloqueio desbloqueio cartao', 'nome sair spc', 'quanto tempo nome sair', 'tempo nome sair', 'tempo nome sair spc', 'quanto tempo nome']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index,topic in enumerate(nmf_model.components_):\n",
    "    print(f'TOP WORDS FOR TOPIC #{index}')\n",
    "    print([tfidf.get_feature_names()[i] for i in topic.argsort()[-20:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" topic_results = nmf_model.transform(dtm)\n",
    "topic_results.shape\n",
    "topic_results[0]\n",
    "topic_results.argmax(axis=1) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" df['Assunto'] = topic_results.argmax(axis=1) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
